{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SF DST Car Price Prediction\n\nЦель проекта: Прогнозирование стоимости автомобиля по характеристикам.\n\nДанный проект в рамках курса \"Специализация Data Science\" был разделен на два юнита. В каждом из которых нужно было реализовать отдельные задачи. \n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import f1_score\n\nfrom tqdm.notebook import tqdm\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom tqdm import tqdm\n\nimport re\n\nimport pandas_profiling as PP\nimport category_encoders as ce\n\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip freeze > requirements.txt\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"VERSION    = 1\nDIR_TRAIN  = '../input/train-cars/' # подключил к ноутбуку свой внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price/'\nVAL_SIZE   = 0.33   # 33%\nN_FOLDS    = 5\n\n# CATBOOST\nITERATIONS = 1000\nLR         = 1e-3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepare = pd.read_csv('../input/for-preparation/backup_bmw.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepare","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(DIR_TRAIN+'mega_train.csv') #really huge train dataset\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.replace('no_data', np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = PP.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По какой-то причине цена определилась как object type."},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = train.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = train.select_dtypes(include=['object']).drop(['price'], axis = 1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Numeric features are: {numeric_features} \\n',\n     f'Categorical features are: {categorical_features}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive solver + category encoder choosing"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_list = [ce.backward_difference.BackwardDifferenceEncoder, \n               ce.basen.BaseNEncoder,\n               ce.binary.BinaryEncoder,\n                ce.cat_boost.CatBoostEncoder,\n                ce.hashing.HashingEncoder,\n                ce.helmert.HelmertEncoder,\n                ce.james_stein.JamesSteinEncoder,\n                ce.one_hot.OneHotEncoder,\n                ce.leave_one_out.LeaveOneOutEncoder,\n                ce.m_estimate.MEstimateEncoder,\n                ce.ordinal.OrdinalEncoder,\n                ce.polynomial.PolynomialEncoder,\n                ce.sum_coding.SumEncoder,\n                ce.target_encoder.TargetEncoder,\n                ce.woe.WOEEncoder\n                ]\n\nfor encoder in encoder_list:\n    \n    numeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('woe', encoder())])\n    \n    preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n    \n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', RandomForestClassifier(n_estimators=500))])\n    \n    model = pipe.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    print(encoder)\n    print(f1_score(y_test, y_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drive - привод\n# condition - состояние авто\n# customs - таможня\n# ownership - время владения\ncols = ['body_type', 'brand', 'color', 'fuel_type', 'model_date', 'name',\n        'num_of_doors', 'production_date', 'vehicle_config', 'vehicle_transmission',\n               'engine_displacement', 'engine_power', 'description', 'mileage', 'complectation', 'drive',\n               'wheel', 'condition', 'owners', 'PTS', 'customs', 'ownership', 'id']\ntest.columns = cols\ntest['sample'] = np.ones(len(test)) # flag test with 1\ntest['price'] = 0\ntrain.drop_duplicates(inplace=True)\ntarget = train.price\ntrain.replace('no_data', np.nan, inplace=True)\n#train.drop(['idprice', 'Unnamed: 0'], axis=1, inplace=True)\nprint(train.columns, len(train.columns))\ncols = ['body_type', 'brand', 'color', 'fuel_type', 'model_date', 'name',\n        'num_of_doors', 'production_date', 'vehicle_config', 'vehicle_transmission',\n               'engine_displacement', 'engine_power', 'description', 'mileage', 'complectation', 'drive',\n               'wheel', 'condition', 'owners', 'PTS', 'customs', 'ownership', 'id', 'price']\ntrain.columns = cols\ntrain['sample'] = np.zeros(len(train)) # flag train with 0\n\n# some preparation\ntrain.fuel_type.replace({1: 'бензин', 2: 'дизель'}, inplace=True)\ntrain.vehicle_transmission.replace({1: 'автоматическая',\n                                    2: 'механическая',\n                                    3: 'вариатор',\n                                    4: 'роботизированная'}, inplace=True)\ntrain.drive.replace({1: 'передний',\n                    2: 'задний',\n                    3: 'полный',\n                    0: 'не упомянут'}, inplace=True)\n\n# to have same names for the same categories in 'owners' for train and test\nown3, own1, own2 = test.owners.value_counts().index.tolist()\ntrain.owners.replace({3: own3,\n                      1: own1,\n                      2: own2}, inplace=True)\n\n\ntrain.drop(target[target.isnull()].index.tolist(), inplace=True) \ndata1 = pd.concat([train, test])\ndata1.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile = pandas_profiling.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile.to_file(\"car_price_profiling.html\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#regexps for name processing\npattern = re.compile('[0-9]+[a-z]')\npattern1 = re.compile('[A-Z][0-9]')\npattern2 = re.compile('[A-Z][0-9]+[a-z]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_other_cat(col, data, thresh):\n    # make 'other' category in given feature by if the frequency of some class is less than threshold(%)\n    \n    valCount = data[col].value_counts(normalize=True)*100\n    names = valCount[valCount < thresh].index.tolist()\n    return data[col].apply(lambda x: 'other' if x in names else x)\n\ndef fuel_type_prep(other, data):\n    # prepare fuel_type feature\n    \n    if other: # 'электро' & 'гибрид' to 'other'\n        return data.fuel_type.apply(lambda x: 'other' if x in ['гибрид', 'электро'] else x)\n    \n    # consider 'электро' & 'гибрид' as 'бензин'because there are\n    # too smal number of samples ih these categories\n    # 63 in 'электро' & 'гибрид'\n    else:\n        return data.fuel_type.apply(lambda x: 'бензин' if x in ['гибрид', 'электро'] else x)\n    \ndef vehicle_transmission_prep(drop, data):\n    if drop: # there is no samples with category'вариатор' in test data\n        idx = data[data.vehicle_transmission == 'вариатор'].index.tolist()\n        data.drop(idx, inplace=True)\n    #else:\n        # merge 'вариатор' in some category\n\ndef mileage_prep(get_log, data):\n    # get log of mileage feature\n    if get_log:\n        data.mileage = data.mileage.apply(lambda x: np.log(x+1))\n\n\n\ndef owners_prepare(method):\n    if method == 'nan2no':\n        data1.owners.fillna('no_data', inplace=True)\n    elif method == 'popularity':\n        data1.owners.fillna(data.owners.value_counts().idxmax(),\n                          inplace=True)\n    elif method == 'nan2zero':\n        # consider owners feature as numeric\n        data1.owners.replace({own3: 3,\n                    own2: 2,\n                    own1: 1}, inplace=True)\n        data1.fillna(0, inplace=True)\n\n\n\ndef PTS_prepare(method):\n    if method == 'no_data':\n        data1.PTS.fillna('no_data', inplace=True)\n    \n    elif method == 'popularity':\n        data1.PTS.fillna(data.PTS.value_counts().idxmax(),\n                          inplace=True)\n\n\n#\n    \n                                                             \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(df_old, method):\n    #categorical features to encode\n    to_encode = ['use_name','brand','body_type', 'color', 'fuel_type', 'drive', 'PTS', 'vehicle_config']\n    \n    #top configurations\n    configs = [i for i in df_old.vehicle_config.value_counts()[:10]]\n    \n    #Cleaning part\n    df = df_old.copy(deep=True)\n    \n    mean = df.mileage.mean()\n    lower = df.mileage.quantile(0.25)\n    upper = df.mileage.quantile(0.75)\n    \n    print(df.columns)\n    df.body_type = make_other_cat('body_type', data=df, thresh=1)\n    df.color = make_other_cat('color', data=df, thresh=1)\n\n    df.fuel_type = fuel_type_prep(other=False, data=df)\n    vehicle_transmission_prep(drop=False, data=df)\n#     mileage_prep(get_log=True, data=df)\n    df.PTS.fillna('no_data', inplace=True)\n\n    df['mileage'] = df['mileage'].apply(lambda x: 0 if x == 0 else x).apply(lambda x: 1 if (x <= lower and x != 0) else x).apply(\n    lambda x: 2 if x > lower and x<=mean else x).apply(lambda x: 3 if x > mean and x<= upper else x).apply(\n    lambda x: 4 if x > upper else x)\n    \n    df['vehicle_config'] = df['vehicle_config'].apply(lambda x: 'other' if x not in configs else x)\n    \n    df.drive.fillna(df.drive.value_counts().idxmax(), inplace=True)\n    owners_prepare(method='nan2zero')\n    PTS_prepare(method='no_data')\n    ownership_prepare(method='no_data')\n    \n    #deleting all the samples with zero doors (occur only in train part)\n    df = df.drop(df[df.num_of_doors == 0].index.tolist())\n\n    df.engine_displacement = df.engine_displacement.replace({'undefined ': -1, 'undefined LTR': -1})\n    df.engine_displacement = df.engine_displacement.apply(lambda x: str(x).replace('LTR', '')).astype(float)\n    print(df.engine_displacement.isna().value_counts())\n    #converting engine power to float type\n    df.engine_power = df.engine_power.apply(lambda x: str(x).replace('N12', '')).astype(float)\n    \n    for feature in ['model_date', 'num_of_doors', 'mileage', 'production_date', 'engine_power']:\n        df[feature]=df[feature].astype('int32')\n    \n    \n    \"\"\"Feature engineering part\"\"\"\n    #adding age of model and car itself\n    df['model_age'] = 2020 - df.model_date\n    df['car_age'] = 2020 - df.production_date\n    df['age_ratio'] = df['car_age']/df['model_age']\n    df['age_ratio'].fillna(1.0, inplace = True)\n    \n    # define the 'taxes' attribute according to the column 'enginePower'\n    df['taxes'] = fe_add_taxes(df, 'engine_power')\n    #\n    df['class_'] =  fe_add_classe(df, 'name')\n    df['is_ownership'] = df.apply(lambda x: 0 if x.ownership == 'no_data' else 1, axis = 1)\n    df['is_old'] = df.apply(lambda x: 1 if x.car_age != 0 else 0, axis = 1)\n    df['old_and_mtnd'] = df.is_ownership + df.is_old\n    \n    df['description'] = df['description'].fillna('[]')\n    df['description_len'] = df['description'].apply(lambda x: len(x.split()))\n    df['description_word'] = df['description'].apply(lambda x: [str(i).lower() for i in x.split()])\n    \n    df = description_features(df)\n    \n    vectorizer = CountVectorizer()\n    text_feat = vectorizer.fit_transform(df['description'])\n    df['mean'] = text_feat.mean(axis=1)\n    df['sum'] = text_feat.sum(axis=1)\n    \n    df['use_name'] = df['name'].apply(lambda x: str(x.replace('BMW', ' ').replace('Audi', ' ').replace(\n    'Volkswagen', ' ').replace('Kia', ' ').replace('Mercedes', ' ')))\n    \n    label_encoder = LabelEncoder()\n    #Encoding binary features from objects to numbers\n    for column in to_encode:\n        print(column)\n        df[column] = label_encoder.fit_transform(df[column])\n        \n    if method == 'other':    \n        df = pd.get_dummies(df, columns = ['use_name','brand', 'body_type', 'color', 'fuel_type', 'vehicle_config',\n                                           'drive', 'wheel', 'owners', 'PTS', 'engine_displacement'], dummy_na=True)\n    if method == 'cat_boost':\n        df['age_ratio'] = df['age_ratio'].apply(lambda x: int(round(x*100)))\n        df['engine_displacement'] = df['engine_displacement'].apply(lambda x: int(round(x*100)))\n        df['mean'] = df['mean'].apply(lambda x: int(round(x)))\n\n    \"\"\"Dropping unprocessed features\"\"\"    \n    df.drop(['id'], axis=1, inplace=True)\n    object_columns = [s for s in df.columns if df[s].dtypes == 'object']\n    df.drop(object_columns, axis = 1, inplace=True)\n    \n    \n    \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separate Data Preparation for CatBoost and Forests and etc"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For CatBoost\nX_all_cat = prepare_data(data1, 'cat_boost')\n\ntrain_cat = X_all_cat[X_all_cat['sample'] == 0]\nsub_cat = X_all_cat[X_all_cat['sample'] == 1]\n\ny_cat = train_cat.price.values\nX_cat = train_cat.drop(['price', 'sample'], axis=1,)\nprint(X_cat.shape, len(y_cat))\n\nsub_cat.drop(['sample','price'], axis = 1, inplace = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#For other models !!!It's necessary to repeat data downloading again\nX_all_oth = prepare_data(data1, 'other')\n\ntrain_oth = X_all_oth[X_all_oth['sample'] == 0]\nsub_oth = X_all_oth[X_all_oth['sample'] == 1]\n\ny_oth = train_oth.price.values\nX_oth = train_oth.drop(['price', 'sample'], axis=1,)\nprint(X_oth.shape, len(y_cat))\n\nsub_oth.drop(['sample','price'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# СV_randomizedsearch for CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = prepare_data(data1, 'cat_boost')\n\nx_train = X_all[X_all['sample'] == 0]\nX_sub = X_all[X_all['sample'] == 1]\n\ny = x_train.price.values\nX = x_train.drop(['price', 'sample'], axis=1,)\nprint(X.shape, len(y))\n\nX_sub.drop(['sample','price'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(random_seed = RANDOM_SEED, eval_metric='MAPE')\n\ngrid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10, 15],\n        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n\nrandomized_search_result = model.randomized_search(grid,\n                                                   X=X,\n                                                   y=y,\n                                                   cv = 5,\n                                                   n_iter = 1000,\n                                                   train_size = 0.67,\n                                                   plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.nunique() #for categorical features definition","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models to stack and blend"},{"metadata":{},"cell_type":"markdown","source":"# CatBoostRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_cat, y_cat, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep list of all categorical features in dataset to specify this for CatBoost\ncat_features_ids = np.where(X_train.apply(pd.Series.nunique) < 2000)[0].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = 0.03,\n                          depth = 15,\n                          l2_leaf_reg = 1,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE']\n                         )\ncat.fit(X_train, y_train,\n         cat_features=cat_features_ids,\n         eval_set=(X_test, y_test),\n         verbose_eval=100,\n         use_best_model=True,\n         plot=True\n         )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators = 1000)\n\ngrid = {\n    'criterion': ['mse'],\n    'max_depth': [10,15],\n    'min_samples_split': [2,3],\n    'max_features': ['sqrt', 'log2'],\n    'oob_score': [True],\n    'random_state': [42]\n}\n    \nreg = GridSearchCV(rf, grid, cv = N_FOLDS)\nreg.fit(X_oth,y_oth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mape(y_test, reg.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreeRegressor(max_depth = 15, random_state = RANDOM_SEED)\nboost = GradientBoostingRegressor(random_state = RANDOM_SEED)\ngrid = {\n    'loss': ['ls','huber'],\n    'learning_rate':[0.05, 0.1],\n    'max_depth': [10,15],\n    'max_features': ['sqrt', 'log2'],\n    'init': [et],\n    'n_iter_no_change':[100]\n}\n\ngb = GridSearchCV(boost, grid, cv = N_FOLDS)\ngb.fit(X_oth,y_oth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mape(y_test, gb.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AdaBoost Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreeRegressor(max_depth = 15, random_state = RANDOM_SEED)\nada_bst = AdaBoostRegressor(et, n_estimators=1000, random_state=RANDOM_SEED)\ngrid = {\n    'loss': ['square'],\n    'learning_rate': [0.1, 0.05, 0.03]\n}\nada = GridSearchCV(ada_bst, grid, cv = N_FOLDS)\nada.fit(X_oth,y_oth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking and Blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [reg, cat, gb, ada]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\ndef blending_pred(models, sample_submission):\n    for model in tqdm(models):\n        if str(model) == '<catboost.core.CatBoostRegressor object at 0x7f9715f32690>':\n            pred_subm = model.predict(sub_cat)\n        else:\n            pred_subm = model.predict(sub_oth)\n        sample_submission[str(model)[:6]] = pred_subm\n    sample_submission['price'] = sample_submission.iloc[:,2:].mean(axis=1)\n    sample_submission[['id', 'price']].to_csv('submission_blending.csv', index=False)\n    sample_submission.head(10)\n    \nblending_pred(models, sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\ndef stacking_pred(models, sample_submission):\n    meta_set = pd.DataFrame()\n    meta_sub = pd.DataFrame()\n    for model in models:\n        if str(model) == '<catboost.core.CatBoostRegressor object at 0x7f9715f32690>':\n            meta_set[str(model)] = model.predict(X_cat)\n        else:\n            print(str(model))\n            meta_set[str(model)] = model.predict(X_oth)\n    for model in models:\n        if str(model) == '<catboost.core.CatBoostRegressor object at 0x7f9715f32690>':\n            meta_sub[str(model)] = model.predict(sub_cat)\n        else:\n            meta_sub[str(model)] = model.predict(sub_oth)\n    meta_set['target'] = y_cat\n    regr = RandomForestRegressor(n_jobs = -1)\n    regr.fit(meta_set.drop('target' , axis = 1), meta_set.target)\n    sample_submission['price'] = regr.predict(meta_sub)\n    print(sample_submission[:10])\n    sample_submission.to_csv('submission_stacking.csv', index = False)\nstacking_pred(models, sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"![](https://i.ibb.co/6rmj4Kh/photo-2020-09-18-16-39-34.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\nsample_submission['price'] = cat.predict(sub_cat)\nsample_submission.to_csv('cat.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}