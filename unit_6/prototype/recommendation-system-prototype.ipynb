{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Global settings"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime, timedelta\nimport json\n\nimport pandas_profiling\nimport nltk\n\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import wordnet, stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom scipy import sparse \n\nimport pickle\n\nfrom tqdm._tqdm_notebook import tqdm_notebook\ntqdm_notebook.pandas()\n\n\nfrom lightfm import LightFM\nfrom lightfm.cross_validation import random_train_test_split\nfrom lightfm.evaluation import auc_score, precision_at_k, recall_at_k\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n","execution_count":2,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Global settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"COL_USER = \"userid\"\nCOL_ITEM = \"itemid\"\nCOL_RATING = \"overall\"\nCOL_PREDICTION = \"rating\"\nCOL_TIMESTAMP = \"timestamp\"\nstop_words = stopwords.words(\"english\")\n\nLR = 0.07\nLOSS_FUNCTION = 'logistic'\nLEARNING_SCHEDULE = 'adagrad'\nRANDOM_STATE = 42\n\nNUM_THREADS = 4 #число потоков\nNUM_COMPONENTS = 30 #число параметров вектора \nNUM_EPOCHS = 20 #число эпох обучения\n","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 2. DATA"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Data downloading"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.read_csv('../input/recommendationsv4/train.csv')\ntrain = pd.read_csv('../input/processed-data/train_processed(2).csv')\ntest = pd.read_csv('../input/recommendationsv4/test.csv')\nsubmission = pd.read_csv('/kaggle/input/recommendationsv4/sample_submission.csv')\n\n# reading metadata json\nwith open('/kaggle/input/recommendationsv4/meta_Grocery_and_Gourmet_Food.json') as f:\n    meta_list = []\n    for line in f.readlines():\n        meta_list.append(json.loads(line))\n        \nmeta = pd.DataFrame(meta_list)\n\n# dropping duplicates\ntrain.drop_duplicates(inplace = True)\n\n# merging train and meta on asin column (Amazon Standard Identification Number)\ntrain = pd.merge(train, meta, on='asin')\ntest = pd.merge(test, meta, on='asin')","execution_count":4,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.to_csv('train.csv') #checkpoint\n# test.to_csv('test.csv')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(meta) #to leave some RAM","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Data understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":7,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 876561 entries, 0 to 876560\nData columns (total 33 columns):\n #   Column          Non-Null Count   Dtype  \n---  ------          --------------   -----  \n 0   Unnamed: 0      876561 non-null  int64  \n 1   overall         876561 non-null  float64\n 2   verified        876561 non-null  bool   \n 3   reviewTime      876561 non-null  object \n 4   asin            876561 non-null  object \n 5   reviewerName    876381 non-null  object \n 6   reviewText      876065 non-null  object \n 7   summary         876195 non-null  object \n 8   unixReviewTime  876561 non-null  int64  \n 9   vote            121610 non-null  object \n 10  style           455492 non-null  object \n 11  image_x         7254 non-null    object \n 12  userid          876561 non-null  int64  \n 13  itemid          876561 non-null  int64  \n 14  rating          876561 non-null  float64\n 15  sample          876561 non-null  int64  \n 16  timestamp       876561 non-null  object \n 17  category        876561 non-null  object \n 18  description     803859 non-null  object \n 19  title           876561 non-null  object \n 20  brand           870281 non-null  object \n 21  rank            839158 non-null  object \n 22  also_view       487527 non-null  object \n 23  main_cat        875596 non-null  object \n 24  price           608169 non-null  object \n 25  also_buy        752810 non-null  object \n 26  image_y         781854 non-null  object \n 27  date            12909 non-null   object \n 28  feature         147926 non-null  object \n 29  details         861055 non-null  object \n 30  similar_item    1194 non-null    object \n 31  tech1           4609 non-null    object \n 32  fit             0 non-null       object \ndtypes: bool(1), float64(2), int64(5), object(25)\nmemory usage: 221.5+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":8,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 292125 entries, 0 to 292124\nData columns (total 27 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   verified        292125 non-null  bool  \n 1   reviewTime      292125 non-null  object\n 2   asin            292125 non-null  object\n 3   reviewerName    292078 non-null  object\n 4   unixReviewTime  292125 non-null  int64 \n 5   vote            40389 non-null   object\n 6   style           151392 non-null  object\n 7   image_x         2407 non-null    object\n 8   userid          292125 non-null  int64 \n 9   itemid          292125 non-null  int64 \n 10  Id              292125 non-null  int64 \n 11  category        292125 non-null  object\n 12  description     267994 non-null  object\n 13  title           292125 non-null  object\n 14  brand           290003 non-null  object\n 15  rank            279697 non-null  object\n 16  also_view       162484 non-null  object\n 17  main_cat        291791 non-null  object\n 18  price           202470 non-null  object\n 19  also_buy        251120 non-null  object\n 20  image_y         260360 non-null  object\n 21  date            4232 non-null    object\n 22  feature         49137 non-null   object\n 23  details         287053 non-null  object\n 24  similar_item    460 non-null     object\n 25  tech1           1426 non-null    object\n 26  fit             0 non-null       object\ndtypes: bool(1), int64(4), object(22)\nmemory usage: 60.5+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   Unnamed: 0  overall  verified   reviewTime        asin  reviewerName  \\\n0           0      5.0      True   10 4, 2016  B01CPNIEQG       Heather   \n1      190285      5.0     False  03 31, 2017  B01CPNIEQG  Tina McClain   \n2      413566      3.0      True  03 11, 2017  B01CPNIEQG          Ella   \n\n                                          reviewText  \\\n0  these favorit spice collect . use everi day ! ...   \n1           love season chicken ! the flavor great .   \n2  ummm ... .interest spice blend , realli adobo ...   \n\n                                  summary  unixReviewTime vote  ... main_cat  \\\n0                must add spice kitchen !      1475539200  NaN  ...  Grocery   \n1                         love season ! !      1490918400  NaN  ...  Grocery   \n2  It 's bad tast , realli n't call adobo      1489190400    4  ...  Grocery   \n\n   price                                           also_buy  \\\n0  $9.95  [B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...   \n1  $9.95  [B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...   \n2  $9.95  [B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...   \n\n                                             image_y  date  feature  \\\n0  [https://images-na.ssl-images-amazon.com/image...   NaN      NaN   \n1  [https://images-na.ssl-images-amazon.com/image...   NaN      NaN   \n2  [https://images-na.ssl-images-amazon.com/image...   NaN      NaN   \n\n                                             details similar_item tech1  fit  \n0  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n1  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n2  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n\n[3 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>overall</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>vote</th>\n      <th>...</th>\n      <th>main_cat</th>\n      <th>price</th>\n      <th>also_buy</th>\n      <th>image_y</th>\n      <th>date</th>\n      <th>feature</th>\n      <th>details</th>\n      <th>similar_item</th>\n      <th>tech1</th>\n      <th>fit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>10 4, 2016</td>\n      <td>B01CPNIEQG</td>\n      <td>Heather</td>\n      <td>these favorit spice collect . use everi day ! ...</td>\n      <td>must add spice kitchen !</td>\n      <td>1475539200</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$9.95</td>\n      <td>[B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>190285</td>\n      <td>5.0</td>\n      <td>False</td>\n      <td>03 31, 2017</td>\n      <td>B01CPNIEQG</td>\n      <td>Tina McClain</td>\n      <td>love season chicken ! the flavor great .</td>\n      <td>love season ! !</td>\n      <td>1490918400</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$9.95</td>\n      <td>[B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>413566</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>03 11, 2017</td>\n      <td>B01CPNIEQG</td>\n      <td>Ella</td>\n      <td>ummm ... .interest spice blend , realli adobo ...</td>\n      <td>It 's bad tast , realli n't call adobo</td>\n      <td>1489190400</td>\n      <td>4</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$9.95</td>\n      <td>[B01DGZ2B48, B01EZ489AO, B01DH795LM, B01EYW2LC...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   verified   reviewTime        asin   reviewerName  unixReviewTime vote  \\\n0      True   10 1, 2016  B001E5E3X0      Rudys Mom      1475280000  NaN   \n1      True  01 20, 2016  B001E5E3X0  Asteroide 699      1453248000  NaN   \n2      True   02 5, 2017  B001E5E3X0     Tito in CR      1486252800  NaN   \n\n  style image_x  userid  itemid  ...  main_cat   price  \\\n0   NaN     NaN   68877    7506  ...   Grocery  $39.05   \n1   NaN     NaN   58293    7506  ...   Grocery  $39.05   \n2   NaN     NaN   36496    7506  ...   Grocery  $39.05   \n\n                                            also_buy  \\\n0  [B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...   \n1  [B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...   \n2  [B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...   \n\n                                             image_y date feature  \\\n0  [https://images-na.ssl-images-amazon.com/image...  NaN     NaN   \n1  [https://images-na.ssl-images-amazon.com/image...  NaN     NaN   \n2  [https://images-na.ssl-images-amazon.com/image...  NaN     NaN   \n\n                                             details similar_item tech1  fit  \n0  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n1  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n2  \\n      <div class=\"content\">\\n\\n\\n\\n\\n\\n\\n<ul...          NaN   NaN  NaN  \n\n[3 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>unixReviewTime</th>\n      <th>vote</th>\n      <th>style</th>\n      <th>image_x</th>\n      <th>userid</th>\n      <th>itemid</th>\n      <th>...</th>\n      <th>main_cat</th>\n      <th>price</th>\n      <th>also_buy</th>\n      <th>image_y</th>\n      <th>date</th>\n      <th>feature</th>\n      <th>details</th>\n      <th>similar_item</th>\n      <th>tech1</th>\n      <th>fit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>True</td>\n      <td>10 1, 2016</td>\n      <td>B001E5E3X0</td>\n      <td>Rudys Mom</td>\n      <td>1475280000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>68877</td>\n      <td>7506</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$39.05</td>\n      <td>[B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>01 20, 2016</td>\n      <td>B001E5E3X0</td>\n      <td>Asteroide 699</td>\n      <td>1453248000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>58293</td>\n      <td>7506</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$39.05</td>\n      <td>[B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>02 5, 2017</td>\n      <td>B001E5E3X0</td>\n      <td>Tito in CR</td>\n      <td>1486252800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36496</td>\n      <td>7506</td>\n      <td>...</td>\n      <td>Grocery</td>\n      <td>$39.05</td>\n      <td>[B005P7YSG0, B005P7YQ7Q, B001M0A8Y0, B004AM21B...</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>\\n      &lt;div class=\"content\"&gt;\\n\\n\\n\\n\\n\\n\\n&lt;ul...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2.3 Data transformation\n### 2.3.1 Simple cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_timestamp(df):\n    \"\"\"converting unixtime to datetime\"\"\"\n    return df.apply(\n    lambda x:  datetime.utcfromtimestamp(x['unixReviewTime']).strftime('%Y-%m-%d'), axis = 1)\ntrain[COL_TIMESTAMP] = get_timestamp(train)\ntest[COL_TIMESTAMP] = get_timestamp(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.main_cat = train.main_cat.fillna('Other') #filling empty categories with \"other\"\ntest.main_cat = test.main_cat.fillna('Other')\n\ndic_verified = {\n    True: 1,\n    False: 0\n}\ntrain['verified'] = train['verified'].map(dic_verified) #replacing \"verified\"-feature with ints\ntest['verified'] = test['verified'].map(dic_verified)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.1 Brief feature engineering"},{"metadata":{},"cell_type":"markdown","source":"For faster execution and to not concentrate too much on feature processing, I'll make features only from review summaries and titles (because it may contain such information as \"non-gluten\", \"halal\", \"vegetarian\", brands, specific product types references and so on."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nstemmer = PorterStemmer()\n\ndef get_sentence(sentence, cond = \"not\"):\n    \"\"\"tokenizing sentences in review and deleting stopwords\"\"\"\n    if cond ==\"stem\":\n        words = nltk.word_tokenize(sentence)\n        without_stop_words = [stemmer.stem(word) for word in words if not word in stop_words]\n    else: without_stop_words = [word for word in sentence.split(' ') if not word in stop_words]\n    return ' '.join(without_stop_words)\n\ndef get_features(series):\n    vectorizer = CountVectorizer(min_df = 0.05) # I wanted to try tfidf, but these amount of RAM is quiet limited to have such\n    list_rvw = series.fillna('noreview') # a variety of types\n    values = vectorizer.fit_transform(list_rvw)\n\n    # Get the features as a pandas DataFrame\n    feature_names = vectorizer.get_feature_names()\n    return pd.DataFrame(values.toarray(), columns = feature_names)","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's possible to lemmatize features, but I won’t do it for now because lemmatization on this dataset would be a time-consuming procedure. Stemming would be a better option."},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting lemmatized summary sentences and tokenized titles\n#train['summary'] = train['summary'].progress_apply(lambda x: str(get_sentence(x, \"stem\")) if type(x) == str else x)\ntrain['token_title'] = train['title'].progress_apply(lambda x: str(get_sentence(x)) if type(x) == str else x)","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=876561.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59cc0a98104438eb309474cd94dd09b"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extruding feature from summaries and titles\n# summary_features = get_features(train['summary'])\n# summary_features['itemid'] = train['itemid']\ntitle_features = get_features(df_train['token_title'])","execution_count":23,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-3c333c34bfee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summary_features = get_features(train['summary'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summary_features['itemid'] = train['itemid']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtitle_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"]}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"title_features['itemid'] = train['itemid']","execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'title_features' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-12efe0af24a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'title_features' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = ['overall', 'verified', 'unixReviewTime',\n       'vote',  'userid', 'itemid',\n       'rating', 'main_cat']\ndf_train = train.loc[:,lst]","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(train)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summary_features.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summary_features.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_features = title_features.loc[:,'bag':'itemid']\ntitle_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(title_features, on = 'itemid', how='left')\ntrain = train.merge(summary_features, on = 'itemid', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['also_buy'] = train['also_buy'].replace('[','').replace(']','')\n# also_buy = train['itemid'].join(train['also_buy'].str.get_dummies(sep = ','))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_features #count-vectorized features based on summaries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.vote.fillna(0, inplace = True)\ndf_train['overall'] = df_train['overall'].apply(lambda x: int(x))\ndf_train['rating'] = df_train['overall'].apply(lambda x: int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(train) #to leave some RAM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary_features['itemid'] = train['itemid']\n# summary_features['vote'] = train['vote']\n# features_item = summary_features.groupby(by = 'itemid').sum()\n# features_item['itemid'] = features_item.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv('df_train.csv') #checkpoint\ndf_test.to_csv('df_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 2.3.2 Further data preparation for LightFM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train = pd.read_csv('../input/last-attempt/df_train.csv') #load from checkpoint\n# df_test = pd.read_csv('../input/last-attempt/df_test.csv')\n# with open('../input/last-attempt/model(1).pkl', 'rb') as f:\n#     model = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_user_train = df_train[['userid', 'verified', 'vote']]\nfeatures_item_train = df_train[['itemid', 'main_cat', 'five',\n                                'good', 'great', 'love', 'star',\n                                'tast','bag', 'bags', 'box', 'chocolate',\n                                'coffee', 'count', 'dark', 'free', 'gluten', 'organic',\n                                'ounce', 'oz', 'pack', 'sugar', 'tea']]\ndf_train = df_train[['userid','itemid','rating']]\ndf_test = test[['userid','itemid']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Item featurs building"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_items(item, features):\n    item_f = []\n    col = []\n    unique_f1 = []\n    for column in features.drop([item], axis=1):\n        col += [column]*len(features[column].unique())\n        unique_f1 += list(features[column].unique())\n    for x,y in zip(col, unique_f1):\n        res = str(x)+ \":\" +str(y)\n        item_f.append(res)\n        print(res)\n    return item_f\n\nitem_f_train = get_items('itemid', features_item_train)\nuser_f_train = get_items('userid', features_user_train)\nitem_f_test = get_items('itemid', features_item_test)\nuser_f_test = get_items('userid', features_user_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightfm.data import Dataset\n# we call fit to supply userid, item id and user/item features\ndataset1 = Dataset()\ndataset1.fit(\n        df_train['userid'].unique(), # all the users\n        df_train['itemid'].unique(), # all the items\n        user_features = user_f_train,\n        item_features = item_f_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(interactions, weights) = dataset1.build_interactions([(x[0], x[1], x[2]) for x in df_train.values ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pattern = [x + ':' for x in features_item_train.drop(['itemid'], axis=1)]\n\ndef make_feat_list(llist, pattern):\n    result = list()\n    for x,y in zip(item_pattern,llist):\n        res = str(x) +\"\"+ str(y)\n        result.append(res)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ad_subset = features_item_train.drop(['itemid'], axis=1)\nad_list = [x.tolist() for x in ad_subset.values]\nitem_feature_list = []\nfor item in ad_list:\n    item_feature_list.append(make_feat_list(item, item_pattern))\nprint(f'Sample: {item_feature_list[0:5]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_tuple = list(zip(features_item_train.itemid, item_feature_list))\nprint(f'Sample:{item_tuple[0:5]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_features_train = dataset1.build_item_features(item_tuple, normalize= False)\nitem_features_train.todense()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Building user features"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_pattern = [x + ':' for x in features_user_train.drop(['userid'], axis=1)]\nad_subset = features_user_train.drop(['userid'], axis=1)\nad_list = [x.tolist() for x in ad_subset.values]\nuser_feature_list = []\nfor item in ad_list:\n    item_feature_list.append(make_feat_list(item, user_pattern))\nprint(f'Sample: {item_feature_list[0:5]}')\n\nuser_tuple = list(zip(features_user_train.userid, user_feature_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_features_train = dataset1.build_user_features(user_tuple, normalize= False)\nuser_features_train.todense()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.3 Model creation for production"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# dictionaries of user/item/features names\nuser_id_map, user_feature_map, item_id_map, item_feature_map = dataset1.mapping()\n\nmodel = LightFM(\n    learning_rate=LR,\n    loss=LOSS_FUNCTION,\n    no_components=NUM_COMPONENTS,\n    learning_schedule = LEARNING_SCHEDULE,\n    random_state = RANDOM_STATE\n)\n\nfrom tqdm.notebook import tqdm\npbar = tqdm()\n\nmodel.fit(interactions, # spase matrix representing whether user and item interacted\n    user_features = user_features_train,\n    item_features = item_features_train, #user and item features sparse matrices\n    sample_weight = weights, # represents how much users and items are interacting or ratings\n    epochs=NUM_EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.3 Precision and recall at k score calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"prec_score = precision_at_k(\n                     model,\n                     df_train,\n                     num_threads=NUM_THREADS,\n                     k=10,\n                    item_features=item_features_train,\n                    user_features=user_features_train).mean()\n \nrecall_at_k = recall_at_k(model,\n                     df_train,\n                     num_threads=NUM_THREADS,\n                     k=10,\n                    user_features=user_features_train,\n                    item_features=item_features_train).mean()\n\nprint(recall_at_k,prec_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 2.3.4 Pickling model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create an variable to pickle and open it in write mode\nmodel_pickle = open('model.pkl', 'wb')\npickle.dump(model, model_pickle)\nmodel_pickle.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.5 Predict/submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_ids = df_test.userid.apply(lambda x: user_id_map[x])\nitem_ids = df_test.itemid.apply(lambda x: item_id_map[x])\npreds = model.predict(user_ids, item_ids, user_features=user_features_train, item_features=item_features_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.min(), preds.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalized_preds = (preds - preds.min())/(preds - preds.min()).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalized_preds.min(), normalized_preds.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/recommendationsv4/sample_submission.csv')\nsubmission['rating']= normalized_preds\nsubmission.to_csv('submission_log.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_log.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.6 Extruding embeddings for application"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_biases, item_embeddings = model.get_item_representations(features=item_features_train)\nuser_biases, user_embeddings = model.get_user_representations(features=user_features_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_emb_pickle = open('item_emb.pkl', 'wb')\nuser_emb_pickle = open('user_emb.pkl', 'wb')\npickle.dump(item_embeddings, item_emb_pickle)\npickle.dump(user_embeddings, user_emb_pickle)\nitem_emb_pickle.close()\nuser_emb_pickle.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install nmslib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nmslib\n#search graph\nnms_idx_i = nmslib.init(method='hnsw', space='cosinesimil')\nnms_idx_u = nmslib.init(method='hnsw', space='cosinesimil')\n \n#adding items tograph\nnms_idx_i.addDataPointBatch(item_embeddings)\nnms_idx_i.createIndex(print_progress=True)\nnms_idx_u.addDataPointBatch(user_embeddings)\nnms_idx_u.createIndex(print_progress=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting nearest items on the graph\ndef nearest_items_nms(itemid, index, n=10):\n    nn = index.knnQuery(item_embeddings[itemid], k=n)\n    return nn\n\ndef nearest_items_nms_u(itemid, index, n=10):\n    nn = index.knnQuery(user_embeddings[itemid], k=n)\n    return nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbm = nearest_items_nms_u(14112,nms_idx_u)[0]\ndf_train[df_train.itemid.isin(nbm)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 3. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"* Score действительно падает при добавлении матрицы фичей, но по моему мнению все равно важно опираться на признаки относящиеся к составу и специфике продукта. В этом плане достаточно информативными оказались заголовки, токенизацией которых я и генерировал большинство признаков. Поэтому я не делал упор на достижение сильно большего чем бейзлайн показателя.\n* В качестве метрики я бы скорее использовал не roc auc, а precision at k и recall at k. Так как класс \"релевантных товаров\" для нас интереснее чем класс \"нерелеватных\". И нам интересно насколько хорошо модель вычисляет именно релевантные товары при данных базовых вероятностях.\n* Проблемой оказалась достаточно большая ресурсоемкость предподготовки модели и самой модели, что отчасти решалось удалением неиспользуемых переменных."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}