{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\n\nimport requests\nfrom bs4 import BeautifulSoup","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_auto(suburl):\n    \"\"\"Function to parse particular unit\"\"\"\n    sub_my_columns = ['bodyType', 'brand', 'color', 'fuelType',\n                  'modelDate', 'name', 'numberOfDoors', 'productionDate',\n                  'vehicleConfiguration', 'vehicleTransmission', 'engineDisplacement', 'enginePower',\n                  'description', 'mileage', 'complectation', 'drive', 'hand', 'condition', 'owners',\n                  'PTS', 'customs', 'owningTime', 'id' 'price']\n    auto_parse = sub_my_columns[:13]\n    \n    car = pd.Series(index = sub_my_columns)\n    sub_r = requests.get(suburl, headers={'User-Agent': 'Mozilla/5.0'})\n    sub_r.encoding = 'utf-8'\n    soup = BeautifulSoup(sub_r.text, 'html.parser')\n    for chrs in auto_parse:\n        #data we find is particularly located in meta with almost exactly the same itemprops as mentioned in test dataset\n        if chrs == 'bodyType':\n            try:\n                car[chrs] = soup.find('meta', itemprop=chrs)['content'].split(' ')[0]\n            except:\n                car[chrs] = 'no_data'\n        else:\n            try:\n                car[chrs] = soup.find('meta', itemprop=chrs)['content']\n            except:\n                car[chrs] = 'no_data'\n                \n            try:\n                car['price'] = float(soup.find('meta', itemprop='price')['content'])\n            except:\n                car['price'] = 'no_data'\n                \n    #The rest of the data we'll awkwardly parse from tech list by html tags  \n    try:\n        car['mileage'] = float(soup.find('li', class_=\"CardInfo__row CardInfo__row_kmAge\").text.replace(\n            'Пробег','').replace('км','').replace(u'\\xa0', u''))\n    except:\n        car['mileage'] = 0.0\n   \n    try:\n        car['complectation'] = soup.find('li',\n                                     class_=\"CardInfoGrouped__row CardInfoGrouped__row_complectation_name\").text.replace(\n                                    'Комплектация', '')\n    except:\n        car['complectation'] = 'no_data'\n        \n    try:\n        car['hand'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_wheel\").text.replace(\n            'Руль','')\n    except:\n        car['hand'] = 'левый'\n    \n    try:\n        car['drive'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_drive\").text.replace(\n            'Привод','')\n    except:\n        car['drive'] = 'no_data'\n        \n    try:\n        car['condition'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_state\").text.replace(\n            'Состояние','')\n    except:\n        car['condition'] = 'no_data'\n        \n    try:\n        car['owners'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_ownersCount\").text.replace(\n            'Владельцы','').replace(u'\\xa0', u' ')\n    except:\n        car['owners'] = 'no_data'\n        \n    try:\n        car['PTS'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_pts\").text.replace(\n            'ПТС','')\n    except:\n        car['PTS'] = 'no_data'\n    \n    try:\n        car['customs'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_customs\").text.replace(\n            'Таможня','')\n    except:\n        car['customs'] = 'no_data'\n    \n    try:\n        car['owningTime'] = soup.find('li', class_=\"CardInfo__row CardInfo__row_owningTime\").text.replace(\n            'Владение','')\n    except:\n        car['owningTime'] = 'no_data'\n    \n    try:\n        car['id'] = int(soup.find('div', title=\"Идентификатор объявления\").text.replace('№ ',''))\n    except:\n        car['id'] = 'no_data'\n    return (car)\n    \n        \ndef parse_autoru(x):\n    \"\"\"General parsing function\"\"\"\n    my_columns = ['bodyType', 'brand', 'color', 'fuelType',\n                  'modelDate', 'name', 'numberOfDoors', 'productionDate',\n                  'vehicleConfiguration', 'vehicleTransmission', 'engineDisplacement', 'enginePower',\n                  'description', 'mileage', 'complectation', 'drive', 'hand', 'condition', 'owners',\n                  'PTS', 'customs', 'owningTime', 'id' 'price']\n    df = pd.DataFrame(columns = my_columns)\n    url = 'https://auto.ru/moskva/cars/' + x + '/all/?page='\n    suburl = []\n    for i in range(1,100):\n        r = requests.get(url+str(i), headers={'User-Agent': 'Mozilla/5.0'})\n        r.encoding = 'utf-8'\n        main_soup = BeautifulSoup(r.text, 'html.parser')\n        links = main_soup.find_all('a', class_=\"Link ListingItemTitle-module__link\")\n        for link in links:\n            df = df.append(get_auto(link['href']), ignore_index = True)\n            df.to_excel('backup_train.xls')\n        time.sleep(np.random.randint(1,2))\n    return df\n                   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_brand = 'mercedes'\ndata = parse_autoru(car_brand)\ndata.to_excel(car_brand + '_train.xls')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Space"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}